{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaJDq1nEt0v4"
   },
   "source": [
    "# **FedProx in Fluke**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJa7IY0wBrTq"
   },
   "source": [
    "# New federated algorithm with `fluke`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blY0W5UsBrTr"
   },
   "source": [
    "This tutorial will guide you through the steps required to implement a new federated learning algorithm that can be tested with ``fluke``.\n",
    "\n",
    "```{attention}\n",
    "This tutorial does not go into the details of the implementation, but it provides a quick overview of the steps required to implement a new federated learning algorithm.\n",
    "```\n",
    "\n",
    "Try this notebook: [![Open in Colab](https://img.shields.io/badge/Open_in_Colab-blue?style=flat-square&logo=google-colab&logoColor=yellow&labelColor=gray)\n",
    "](https://colab.research.google.com/github/CasellaJr/Fluke-tutorial-ECAI25/blob/main/1_fluke_custom_alg.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cz3rwhSFBrTr"
   },
   "source": [
    "## Install `fluke` (if not already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyGiUXc9BrTs",
    "outputId": "403430df-d252-4a19-9851-b9436ec9bf45",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install fluke-fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJkmAaYEBrTs"
   },
   "source": [
    "## Implementing a custom algorithm\n",
    "\n",
    "To keep it simple, we use a very easy example of a new FL algorithm.\n",
    "Let's say we want define a new federated algorithm with these two characteristics:\n",
    "- At each round, the server aggregates the parameters via the **median** (conversely to the typical averaging strategy)\n",
    "- A client will follow the **FedProx** algorithm (i.e., adding a proximity penalty loss)\n",
    "\n",
    "Let's start with the client. The only thing the client does differently from the standard FedAvg client is to add a penalty term to the loss function. The rest of the logic is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qC0qpjCSBrTt"
   },
   "source": [
    "Most of the server's behaviour is the same as in `FedAvg` that is already implemented in `fluke.server.Server`.\n",
    "\n",
    "## Implementing the client-side logic\n",
    "\n",
    "Let's implement the client-side logic. Also in this case we can start from the `FedAvg` client that is already implemented in `fluke.client.Client` and modify it to fit our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_i(w) = f_i(w) + \\frac{\\mu}{2} \\| w - w^{(t)} \\|^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siOzA_MyBrTt"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "\n",
    "from fluke.client import Client\n",
    "from fluke.server import Server\n",
    "from fluke.data import FastDataLoader\n",
    "from fluke.config import OptimizerConfigurator\n",
    "from fluke.utils import clear_cuda_cache\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "class MyFedProxClient(Client):\n",
    "    def __init__(\n",
    "        self,\n",
    "        index: int,\n",
    "        train_set: FastDataLoader,\n",
    "        test_set: FastDataLoader,\n",
    "        optimizer_cfg: OptimizerConfigurator,\n",
    "        loss_fn: Module,\n",
    "        local_epochs: int,\n",
    "        fine_tuning_epochs: int = 0,\n",
    "        clipping: float = 0,\n",
    "        mu: float = 0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            index=index,\n",
    "            train_set=train_set,\n",
    "            test_set=test_set,\n",
    "            optimizer_cfg=optimizer_cfg,\n",
    "            loss_fn=loss_fn,\n",
    "            local_epochs=local_epochs,\n",
    "            fine_tuning_epochs=fine_tuning_epochs,\n",
    "            clipping=clipping,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.hyper_params.update(mu=mu)\n",
    "\n",
    "    def _proximal_loss(self, local_model: Module, global_model: Module) -> float:\n",
    "        proximal_term = 0.0\n",
    "        for w, w_t in zip(local_model.parameters(), global_model.parameters()):\n",
    "            if w_t.requires_grad:\n",
    "                proximal_term += (w - w_t).norm(2) ** 2\n",
    "        return proximal_term\n",
    "\n",
    "    # we override the fit method to implement our training \"strategy\"\n",
    "    def fit(self, override_local_epochs: int = 0) -> float:\n",
    "        epochs: int = (\n",
    "            override_local_epochs if override_local_epochs > 0 else self.hyper_params.local_epochs\n",
    "        )\n",
    "        # We need a copy of the global model for the proximal term\n",
    "        W = deepcopy(self.model).to(self.device)\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "\n",
    "        if self.optimizer is None:\n",
    "            self.optimizer, self.scheduler = self._optimizer_cfg(self.model)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for _ in range(epochs):\n",
    "            loss = None\n",
    "            for _, (X, y) in enumerate(self.train_set):\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                y_hat = self.model(X)\n",
    "\n",
    "                # This is actually the only change compared to standard FedAvg\n",
    "                loss = self.hyper_params.loss_fn(y_hat, y) + (\n",
    "                    self.hyper_params.mu / 2\n",
    "                ) * self._proximal_loss(self.model, W)\n",
    "                #\n",
    "\n",
    "                loss.backward()\n",
    "                self._clip_grads(self.model)\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            self.scheduler.step()\n",
    "\n",
    "        running_loss /= epochs * len(self.train_set)\n",
    "        self.model.cpu()\n",
    "        W.cpu()\n",
    "        clear_cuda_cache()\n",
    "        return running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLl0JVgdBrTu"
   },
   "source": [
    "## Implementing the new federated algorithm\n",
    "\n",
    "Now, we only need to put everything together in a new class that inherits from `fluke.algorithms.CentralizedFL` specifying the server and client classes we just implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQITNdlLBrTu"
   },
   "outputs": [],
   "source": [
    "from fluke.algorithms import CentralizedFL\n",
    "\n",
    "class MyFedProx(CentralizedFL):\n",
    "\n",
    "    def get_client_class(self) -> type[Client]:\n",
    "        return MyFedProxClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnN3xfogBrTu"
   },
   "source": [
    "Everything is ready! Now we can test our new federated algorithm with `fluke`.\n",
    "Now, we actually implemented FedProx, in the following we will implement the median aggregation rule on the server side.\n",
    "\n",
    "## Ready to test the new federated algorithm\n",
    "\n",
    "**NOTE:** The following code is used to set up the experiment using Python API only, but you can also use the YAML configuration files and the CLI as shown in other tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "if6AzKStBrTu"
   },
   "outputs": [],
   "source": [
    "from fluke.data import DataSplitter\n",
    "from fluke.data.datasets import Datasets\n",
    "from fluke import DDict\n",
    "from fluke.utils.log import Log\n",
    "from fluke.evaluation import ClassificationEval\n",
    "from fluke import FlukeENV\n",
    "from fluke.utils import plot_distribution\n",
    "\n",
    "env = FlukeENV()\n",
    "env.set_seed(42) # we set a seed for reproducibility\n",
    "env.set_device(\"cpu\") # we run on cpu but cuda and mps are supported as well\n",
    "\n",
    "# We load the mnist dataset as it is provided by fluke\n",
    "dataset = Datasets.get(\"mnist\", path=\"./data\")\n",
    "\n",
    "# we set the evaluator to be used by both the server and the clients\n",
    "env.set_evaluator(ClassificationEval(eval_every=1, n_classes=dataset.num_classes))\n",
    "\n",
    "splitter = DataSplitter(dataset=dataset,\n",
    "                        distribution=\"iid\")\n",
    "\n",
    "# Client hyperparameters\n",
    "client_hp = DDict(\n",
    "    batch_size=10,\n",
    "    local_epochs=5,\n",
    "    loss=\"CrossEntropyLoss\",\n",
    "    mu=0.3,\n",
    "    optimizer=DDict(\n",
    "      lr=0.01,\n",
    "      momentum=0.9,\n",
    "      weight_decay=0.0001),\n",
    "    scheduler=DDict(\n",
    "      gamma=1,\n",
    "      step_size=1)\n",
    ")\n",
    "\n",
    "# we put together the hyperparameters for the algorithm\n",
    "hyperparams = DDict(client=client_hp,\n",
    "                    server=DDict(weighted=True), # this is the only hyperparameter for the server\n",
    "                    model=\"MNIST_2NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4W0gY-9BrTu"
   },
   "source": [
    "Here is where the new federated algorithm comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "wBsBBwewBrTu",
    "outputId": "5b4ff648-82fc-4d75-8a79-081f438af1f4"
   },
   "outputs": [],
   "source": [
    "algorithm = MyFedProx(\n",
    "    n_clients=10, # 10 clients in the federation\n",
    "    data_splitter=splitter,\n",
    "    hyper_params=hyperparams\n",
    ")\n",
    "\n",
    "plot_distribution(algorithm.clients, plot_type=\"ball\") #mat, ball, bar\n",
    "\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)\n",
    "logger.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ske0exuGBrTu"
   },
   "source": [
    "We only just need to run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897,
     "referenced_widgets": [
      "fe05446f6cb240b8848aa78488cca5d1",
      "0e47311c5d1148778fe523e6afa8c08c",
      "53faf5737e03493abce8f54c4ed26446",
      "9344d77558d2418caa1f150cb77adeb1"
     ]
    },
    "id": "u_lGtbgWBrTu",
    "outputId": "df00d849-c258-4022-e0e4-34e254099841",
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "algorithm.run(n_rounds=3, eligible_perc=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WP2-T9sRSS4"
   },
   "source": [
    "## Comparison with FedAvg in a non-IID scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "f-1Rw-x0RKxp",
    "outputId": "f8e5999b-c285-4c98-a353-fc8d23e3c8fb"
   },
   "outputs": [],
   "source": [
    "from fluke.algorithms.fedavg import FedAVG\n",
    "\n",
    "# Dirichlet non-iid data distribution\n",
    "splitter = DataSplitter(dataset=dataset,\n",
    "                        distribution=\"dir\", dist_args={\"beta\":0.5})\n",
    "\n",
    "fedavg_non_iid = FedAVG(\n",
    "    n_clients=10, # 10 clients in the federation\n",
    "    data_splitter=splitter,\n",
    "    hyper_params=hyperparams\n",
    ")\n",
    "\n",
    "plot_distribution(fedavg_non_iid.clients, plot_type=\"ball\") #mat, ball, bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Log()\n",
    "fedavg_non_iid.set_callbacks(logger)\n",
    "logger.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "56a08f1c13e147a98c9bc1c6fb74fc65",
      "fece904627d64a028804737dc89c6440"
     ]
    },
    "id": "fqZdtpL9W4cR",
    "outputId": "0358a2d7-2526-4e1a-bea4-814fd5da7d89"
   },
   "outputs": [],
   "source": [
    "fedavg_non_iid.run(n_rounds=3, eligible_perc=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769,
     "referenced_widgets": [
      "1eefd828a16a4b4fa5da65c8f71c1acd",
      "9dab618b4d374268a580b09bc5f65625"
     ]
    },
    "id": "eTd6GV9iSX5e",
    "outputId": "d7a7b639-84f9-44ca-e668-0131ae3c6f89"
   },
   "outputs": [],
   "source": [
    "fedprox_non_iid = MyFedProx(\n",
    "    n_clients=10, # 10 clients in the federation\n",
    "    data_splitter=splitter,\n",
    "    hyper_params=hyperparams\n",
    ")\n",
    "\n",
    "logger = Log()\n",
    "fedprox_non_iid.set_callbacks(logger)\n",
    "logger.init()\n",
    "\n",
    "fedprox_non_iid.run(n_rounds=3, eligible_perc=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mihlF2NAyUDX"
   },
   "source": [
    "## Implementing the server-side logic\n",
    "Let's continue with the server. Given the characteristics of the algorithm, the only thing the server does differently from the standard FedAvg server is to use the median to aggregate the parameters, rather than the mean. The primary motivation for using the median is robustness. Averaging is highly susceptible to corrupt or malicious updates, while the median is remarkably resilient. For the same parameter (the first row, first column), you take the values from all 100 devices, line them up in order from smallest to largest, and pick the middle value.\n",
    "The rest of the logic is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Iterable, Sequence\n",
    "\n",
    "class MedianServer(Server):\n",
    "    def aggregate(\n",
    "        self,\n",
    "        eligible: Sequence[Client],\n",
    "        client_models: Iterable[torch.nn.Module]\n",
    "    ) -> None:\n",
    "\n",
    "        # Convert models to list for multiple iterations\n",
    "        models_list = list(client_models)\n",
    "        # Get model parameters\n",
    "        model_params = dict(self.model.named_parameters())\n",
    "\n",
    "        for key in model_params.keys():\n",
    "            tensors = []\n",
    "            for m in models_list:\n",
    "                tensors.append(dict(m.named_parameters())[key].data)\n",
    "\n",
    "            # Stack all parameter values and compute median along the client dimension\n",
    "            stacked = torch.stack(tensors, dim=0)\n",
    "            median_val = torch.median(stacked, dim=0).values\n",
    "            model_params[key].data.copy_(median_val)\n",
    "\n",
    "        self.model.load_state_dict(model_params)\n",
    "\n",
    "        return deepcopy(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "94Ahl6pn0N8S"
   },
   "outputs": [],
   "source": [
    "class MedianFedProx(CentralizedFL):\n",
    "\n",
    "    def get_client_class(self) -> type[Client]:\n",
    "        return MyFedProxClient\n",
    "\n",
    "    def get_server_class(self) -> type[Server]:\n",
    "        return MedianServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769,
     "referenced_widgets": [
      "080117027af549359aa3fbfd118bd57e",
      "53be0febf9d744f0a8e9c6e86c5d5412"
     ]
    },
    "id": "gxmG-cJs8ZGu",
    "outputId": "b20a53c8-b3dc-475e-bc5b-6463733bc484"
   },
   "outputs": [],
   "source": [
    "env.set_seed(42) # we set a seed for reproducibility\n",
    "median_fedprox_non_iid = MedianFedProx(\n",
    "    n_clients=10, # 10 clients in the federation\n",
    "    data_splitter=splitter,\n",
    "    hyper_params=hyperparams\n",
    ")\n",
    "\n",
    "logger = Log()\n",
    "median_fedprox_non_iid.set_callbacks(logger)\n",
    "logger.init()\n",
    "\n",
    "median_fedprox_non_iid.run(n_rounds=3, eligible_perc=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xufNhdSASr1m"
   },
   "source": [
    "## Using a custom model in fluke\n",
    "For the purpose of this tutorial, we will define a very simple neural network for the MNIST dataset. The network will have two hidden layers with ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydPS2TMASvpz"
   },
   "outputs": [],
   "source": [
    "from torch.functional import F\n",
    "\n",
    "class MyMLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(28*28, 100)\n",
    "        self.fc2 = torch.nn.Linear(100, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769,
     "referenced_widgets": [
      "a46c436529cb4463bab4fda0083de3fa",
      "6501db4bfc5b4a878332a5f12679a678"
     ]
    },
    "id": "F6SBgI4WAZl0",
    "outputId": "d8e4473d-277d-4d8c-c6c6-b252785137e2"
   },
   "outputs": [],
   "source": [
    "hyperparams = DDict(client=client_hp,\n",
    "                    server=DDict(weighted=True),\n",
    "                    model=MyMLP()) # we use our custom MLP model\n",
    "\n",
    "median_fedprox_non_iid = MyFedProx(\n",
    "    n_clients=10,\n",
    "    data_splitter=splitter,\n",
    "    hyper_params=hyperparams)\n",
    "\n",
    "logger = Log()\n",
    "median_fedprox_non_iid.set_callbacks(logger)\n",
    "logger.init()\n",
    "\n",
    "median_fedprox_non_iid.run(n_rounds=3, eligible_perc=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3 (ipykernel)",
=======
   "display_name": "fluke-tutorial (3.12.10)",
>>>>>>> 9a1269f7aa249c7a99edf77072740a7039ed8405
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.17"
=======
   "version": "3.12.10"
>>>>>>> 9a1269f7aa249c7a99edf77072740a7039ed8405
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "080117027af549359aa3fbfd118bd57e": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_53be0febf9d744f0a8e9c6e86c5d5412",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finalizing federation... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n",
         "text/plain": "Finalizing federation... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "0e47311c5d1148778fe523e6afa8c08c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1eefd828a16a4b4fa5da65c8f71c1acd": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_9dab618b4d374268a580b09bc5f65625",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finalizing federation... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n",
         "text/plain": "Finalizing federation... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "53be0febf9d744f0a8e9c6e86c5d5412": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53faf5737e03493abce8f54c4ed26446": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_9344d77558d2418caa1f150cb77adeb1",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finalizing federation... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n",
         "text/plain": "Finalizing federation... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "56a08f1c13e147a98c9bc1c6fb74fc65": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_fece904627d64a028804737dc89c6440",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finalizing federation... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n",
         "text/plain": "Finalizing federation... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "6501db4bfc5b4a878332a5f12679a678": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9344d77558d2418caa1f150cb77adeb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dab618b4d374268a580b09bc5f65625": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a46c436529cb4463bab4fda0083de3fa": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_6501db4bfc5b4a878332a5f12679a678",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Finalizing federation... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n",
         "text/plain": "Finalizing federation... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "fe05446f6cb240b8848aa78488cca5d1": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_0e47311c5d1148778fe523e6afa8c08c",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">FL Rounds</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 50%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:48</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">FL Rounds</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 50%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:43</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">FL Rounds</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 50%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:50</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">FL Rounds</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 90%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:10</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">Local Training</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">Local Training</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">Local Training</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n<span style=\"color: #008000; text-decoration-color: #008000\">Local Training</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 80%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n</pre>\n",
         "text/plain": "\u001b[31mFL Rounds\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 50%\u001b[0m \u001b[36m0:00:48\u001b[0m\n\u001b[31mFL Rounds\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 50%\u001b[0m \u001b[36m0:00:43\u001b[0m\n\u001b[31mFL Rounds\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m 50%\u001b[0m \u001b[36m0:00:50\u001b[0m\n\u001b[31mFL Rounds\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[35m 90%\u001b[0m \u001b[36m0:00:10\u001b[0m\n\u001b[32mLocal Training\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n\u001b[32mLocal Training\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n\u001b[32mLocal Training\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n\u001b[32mLocal Training\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[35m 80%\u001b[0m \u001b[36m0:00:00\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "fece904627d64a028804737dc89c6440": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
