{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New federated Aggregation with `fluke`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install `fluke` (if not already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fluke-fl in ./ecai_venv/lib/python3.10/site-packages (0.7.9)\n",
      "Requirement already satisfied: torchvision in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (0.24.0)\n",
      "Requirement already satisfied: pandas in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (2.3.3)\n",
      "Requirement already satisfied: torch in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (2.9.0)\n",
      "Requirement already satisfied: cerberus in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (1.3.7)\n",
      "Requirement already satisfied: requests in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (2.32.5)\n",
      "Requirement already satisfied: typer in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (0.19.2)\n",
      "Requirement already satisfied: hydra-core in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (1.3.2)\n",
      "Requirement already satisfied: diskcache in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (5.6.3)\n",
      "Requirement already satisfied: opacus in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (1.5.4)\n",
      "Requirement already satisfied: tensorboard in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (1.7.2)\n",
      "Requirement already satisfied: wandb in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (0.22.2)\n",
      "Requirement already satisfied: rich in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (14.2.0)\n",
      "Requirement already satisfied: clearml in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (2.0.2)\n",
      "Requirement already satisfied: matplotlib in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (3.10.7)\n",
      "Requirement already satisfied: datasets in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (4.2.0)\n",
      "Requirement already satisfied: numpy in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (2.2.6)\n",
      "Requirement already satisfied: seaborn in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (0.13.2)\n",
      "Requirement already satisfied: pyyaml in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (6.0.3)\n",
      "Requirement already satisfied: omegaconf in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (2.3.0)\n",
      "Requirement already satisfied: torchmetrics in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (1.8.2)\n",
      "Requirement already satisfied: psutil in ./ecai_venv/lib/python3.10/site-packages (from fluke-fl) (7.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.16.0 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (1.17.0)\n",
      "Requirement already satisfied: furl>=2.0.0 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (2.1.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (3.2.5)\n",
      "Requirement already satisfied: referencing<0.40 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (0.37.0)\n",
      "Requirement already satisfied: pyjwt<2.11.0,>=2.4.0 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (2.10.1)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (2.5.0)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (4.25.1)\n",
      "Requirement already satisfied: attrs>=18.0 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (25.4.0)\n",
      "Requirement already satisfied: Pillow>=10.3.0 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (12.0.0)\n",
      "Requirement already satisfied: pathlib2>=2.3.0 in ./ecai_venv/lib/python3.10/site-packages (from clearml->fluke-fl) (2.3.7.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ecai_venv/lib/python3.10/site-packages (from requests->fluke-fl) (2025.10.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./ecai_venv/lib/python3.10/site-packages (from requests->fluke-fl) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ecai_venv/lib/python3.10/site-packages (from requests->fluke-fl) (3.11)\n",
      "Requirement already satisfied: fsspec[http]<=2025.9.0,>=2023.1.0 in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (2025.9.0)\n",
      "Requirement already satisfied: xxhash in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (0.70.16)\n",
      "Requirement already satisfied: filelock in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (3.20.0)\n",
      "Requirement already satisfied: packaging in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (25.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (0.35.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./ecai_venv/lib/python3.10/site-packages (from datasets->fluke-fl) (0.4.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./ecai_venv/lib/python3.10/site-packages (from hydra-core->fluke-fl) (4.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./ecai_venv/lib/python3.10/site-packages (from matplotlib->fluke-fl) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./ecai_venv/lib/python3.10/site-packages (from matplotlib->fluke-fl) (1.4.9)\n",
      "Requirement already satisfied: cycler>=0.10 in ./ecai_venv/lib/python3.10/site-packages (from matplotlib->fluke-fl) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./ecai_venv/lib/python3.10/site-packages (from matplotlib->fluke-fl) (4.60.1)\n",
      "Requirement already satisfied: scipy>=1.2 in ./ecai_venv/lib/python3.10/site-packages (from opacus->fluke-fl) (1.15.3)\n",
      "Requirement already satisfied: opt-einsum>=3.3.0 in ./ecai_venv/lib/python3.10/site-packages (from opacus->fluke-fl) (3.4.0)\n",
      "Requirement already satisfied: jinja2 in ./ecai_venv/lib/python3.10/site-packages (from torch->fluke-fl) (3.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./ecai_venv/lib/python3.10/site-packages (from torch->fluke-fl) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./ecai_venv/lib/python3.10/site-packages (from torch->fluke-fl) (4.15.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./ecai_venv/lib/python3.10/site-packages (from torch->fluke-fl) (3.4.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./ecai_venv/lib/python3.10/site-packages (from pandas->fluke-fl) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./ecai_venv/lib/python3.10/site-packages (from pandas->fluke-fl) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./ecai_venv/lib/python3.10/site-packages (from rich->fluke-fl) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./ecai_venv/lib/python3.10/site-packages (from rich->fluke-fl) (2.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./ecai_venv/lib/python3.10/site-packages (from scikit-learn->fluke-fl) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./ecai_venv/lib/python3.10/site-packages (from scikit-learn->fluke-fl) (1.5.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./ecai_venv/lib/python3.10/site-packages (from tensorboard->fluke-fl) (2.3.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./ecai_venv/lib/python3.10/site-packages (from tensorboard->fluke-fl) (65.5.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./ecai_venv/lib/python3.10/site-packages (from tensorboard->fluke-fl) (1.75.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./ecai_venv/lib/python3.10/site-packages (from tensorboard->fluke-fl) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./ecai_venv/lib/python3.10/site-packages (from tensorboard->fluke-fl) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./ecai_venv/lib/python3.10/site-packages (from tensorboard->fluke-fl) (0.7.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./ecai_venv/lib/python3.10/site-packages (from tensorboard->fluke-fl) (6.33.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in ./ecai_venv/lib/python3.10/site-packages (from torchmetrics->fluke-fl) (0.15.2)\n",
      "Requirement already satisfied: click>=8.0.0 in ./ecai_venv/lib/python3.10/site-packages (from typer->fluke-fl) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./ecai_venv/lib/python3.10/site-packages (from typer->fluke-fl) (1.5.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./ecai_venv/lib/python3.10/site-packages (from wandb->fluke-fl) (2.42.0)\n",
      "Requirement already satisfied: platformdirs in ./ecai_venv/lib/python3.10/site-packages (from wandb->fluke-fl) (4.5.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./ecai_venv/lib/python3.10/site-packages (from wandb->fluke-fl) (3.1.45)\n",
      "Requirement already satisfied: pydantic<3 in ./ecai_venv/lib/python3.10/site-packages (from wandb->fluke-fl) (2.12.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./ecai_venv/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets->fluke-fl) (3.13.0)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in ./ecai_venv/lib/python3.10/site-packages (from furl>=2.0.0->clearml->fluke-fl) (1.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./ecai_venv/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->fluke-fl) (4.0.12)\n",
      "Requirement already satisfied: anyio in ./ecai_venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets->fluke-fl) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./ecai_venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets->fluke-fl) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./ecai_venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets->fluke-fl) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./ecai_venv/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets->fluke-fl) (1.1.10)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./ecai_venv/lib/python3.10/site-packages (from jsonschema>=2.6.0->clearml->fluke-fl) (0.27.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./ecai_venv/lib/python3.10/site-packages (from jsonschema>=2.6.0->clearml->fluke-fl) (2025.9.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./ecai_venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->fluke-fl) (0.1.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./ecai_venv/lib/python3.10/site-packages (from pydantic<3->wandb->fluke-fl) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in ./ecai_venv/lib/python3.10/site-packages (from pydantic<3->wandb->fluke-fl) (2.41.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./ecai_venv/lib/python3.10/site-packages (from pydantic<3->wandb->fluke-fl) (0.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./ecai_venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->fluke-fl) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./ecai_venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->fluke-fl) (3.0.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./ecai_venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->fluke-fl) (0.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./ecai_venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->fluke-fl) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./ecai_venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->fluke-fl) (1.22.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./ecai_venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->fluke-fl) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./ecai_venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->fluke-fl) (2.6.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./ecai_venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->fluke-fl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./ecai_venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets->fluke-fl) (6.7.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./ecai_venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->fluke-fl) (5.0.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./ecai_venv/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets->fluke-fl) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./ecai_venv/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets->fluke-fl) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fluke-fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malicious Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Collection, Sequence, Iterable\n",
    "from torch.nn import Module\n",
    "import torch\n",
    "from fluke.client import Client\n",
    "from fluke.server import Server\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from fluke.data import FastDataLoader\n",
    "\n",
    "class MyClient(Client):\n",
    "    def __init__(self, malicious_percentage=0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.malicious = torch.rand(1).item() < malicious_percentage\n",
    "\n",
    "    def send_model(self) -> None:\n",
    "        if self.malicious:\n",
    "            for param in self.model.parameters():\n",
    "                param.data = torch.randn_like(param)\n",
    "        super().send_model()\n",
    "    \n",
    "    # # If you want malicious client to skip evaluation\n",
    "    # def evaluate(self, evaluator, test_set) -> dict[str, float]:\n",
    "    #     if self.malicious:\n",
    "    #         return {}\n",
    "    #     else:\n",
    "    #         return super().evaluate(evaluator, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label-flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClient(Client):\n",
    "    def __init__(self, malicious_percentage=0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.malicious = torch.rand(1).item() < malicious_percentage\n",
    "        \n",
    "        if self.malicious:\n",
    "            labels = self.train_set.tensors[1]\n",
    "            unique_labels = torch.unique(labels)\n",
    "            \n",
    "            flipped_labels = unique_labels[torch.randperm(len(unique_labels))]\n",
    "\n",
    "            mapping = {old.item(): new.item() for old, new in zip(unique_labels, flipped_labels)}\n",
    "            \n",
    "            flipped = labels.clone()\n",
    "            for old, new in mapping.items():\n",
    "                flipped[labels == old] = new\n",
    "            self.train_set.tensors = (self.train_set.tensors[0], flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-KRUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyServer(Server):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        test_set: FastDataLoader | None,\n",
    "        clients: Sequence[Client],\n",
    "        weighted: bool = False,\n",
    "        lr: float = 1.0,\n",
    "        m: int = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(model, test_set, clients, weighted, lr, **kwargs)\n",
    "        self.hyper_params.update(m=m)\n",
    "\n",
    "\n",
    "    def aggregate(self, eligible: Sequence[Client], client_models: Iterable[Module]) -> None:\n",
    "            \n",
    "            client_models = list(client_models)\n",
    "            n = len(client_models)\n",
    "            f = sum(1 for c in self.clients if c.malicious)\n",
    "            \n",
    "            server_param_items = list(self.model.named_parameters())\n",
    "            param_keys = [k for k, _ in server_param_items]\n",
    "\n",
    "            # get one vector for each client\n",
    "            client_vecs = []\n",
    "            for i, cm in enumerate(client_models):\n",
    "                cm_state = dict(cm.named_parameters()) \n",
    "                parts = [torch.ravel(cm_state[k].data) for k in param_keys]\n",
    "                vec = torch.cat(parts, dim=0) \n",
    "                client_vecs.append(vec)\n",
    "\n",
    "            # put all these vector in a tensor\n",
    "            mat = torch.stack(client_vecs, dim=0)\n",
    "            \n",
    "            # calculate pairwise euclidean distance matrix to extract the scores\n",
    "            dists = torch.cdist(mat, mat, p=2.0)  # shape (n, n)\n",
    "            sq_dists = dists.pow(2)\n",
    "\n",
    "            scores = torch.empty(n)\n",
    "            # For each model i, sort distances to others (exclude self-distance=0)\n",
    "            # and sum the smallest (n - f - 2) distances\n",
    "            nb_small = n - f - 2\n",
    "            for i in range(n):\n",
    "                # distances to others (includes zero at i)\n",
    "                row = sq_dists[i]\n",
    "                # Get sorted distances (ascending)\n",
    "                sorted_row, _ = torch.sort(row)\n",
    "                selected = sorted_row[1: nb_small + 1]\n",
    "                scores[i] = selected.sum()\n",
    "\n",
    "            _, selected_indices = torch.topk(scores, k=self.hyper_params.m, largest=False)\n",
    "\n",
    "            selected_indices = selected_indices.tolist()  # indices of chosen clients\n",
    "\n",
    "            # If m == 1: KRUM\n",
    "            if self.hyper_params.m == 1:\n",
    "                chosen_idx = selected_indices[0]\n",
    "                chosen_state = dict(client_models[chosen_idx].named_parameters())\n",
    "                # Copy parameter tensors into server model\n",
    "                for k in param_keys:\n",
    "                    self.model.state_dict()[k].copy_(chosen_state[k].data)\n",
    "            else:\n",
    "                # Multi-KRUM: average the selected m models elementwise (simple mean)\n",
    "                # We'll build averaged parameters by stacking the selected params and mean them\n",
    "                # Using named_parameters order to assemble results\n",
    "                # Initialize accumulator dict of tensors (float) on server device\n",
    "                accum = {}\n",
    "                for k in param_keys:\n",
    "                    first_t = client_models[selected_indices[0]].state_dict()[k].data\n",
    "                    accum[k] = first_t.clone().detach().float()  # use float accumulation\n",
    "\n",
    "                for idx in selected_indices[1:]:\n",
    "                    cm_state = client_models[idx].state_dict()\n",
    "                    for k in param_keys:\n",
    "                        accum[k].add_(cm_state[k].data)\n",
    "\n",
    "                # divide by m and copy back\n",
    "                for k in param_keys:\n",
    "                    mean_t = (accum[k] / float(self.hyper_params.m)).to(self.model.state_dict()[k].dtype)\n",
    "                    self.model.state_dict()[k].copy_(mean_t)\n",
    "\n",
    "            return deepcopy(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the new federated algorithm\n",
    "\n",
    "Now, we only need to put everything together in a new class that inherits from `fluke.algorithms.CentralizedFL` specifying the server and client classes we just implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.algorithms import CentralizedFL\n",
    "\n",
    "class MyFLAlgorithm(CentralizedFL):\n",
    "\n",
    "    def get_client_class(self) -> type[Client]:\n",
    "        return MyClient\n",
    "\n",
    "    def get_server_class(self) -> type[Server]:\n",
    "        return MyServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is ready! Now we can test our new federated algorithm with `fluke`!\n",
    "\n",
    "## Ready to test the new federated algorithm\n",
    "\n",
    "The rest of the code is the same as in the [First steps with `fluke` API](fluke_quick_api.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.data import DataSplitter\n",
    "from fluke.data.datasets import Datasets\n",
    "from fluke import DDict\n",
    "from fluke.utils.log import Log\n",
    "from fluke.evaluation import ClassificationEval\n",
    "from fluke import FlukeENV\n",
    "\n",
    "env = FlukeENV()\n",
    "env.set_seed(42) # we set a seed for reproducibility\n",
    "env.set_device(\"cpu\") # we use the CPU for this example\n",
    "\n",
    "dataset = Datasets.get(\"mnist\", path=\"./data\")\n",
    "\n",
    "# we set the evaluator to be used by both the server and the clients\n",
    "env.set_evaluator(ClassificationEval(eval_every=1, n_classes=dataset.num_classes))\n",
    "\n",
    "splitter = DataSplitter(dataset=dataset,\n",
    "                        distribution=\"iid\")\n",
    "\n",
    "client_hp = DDict(\n",
    "    batch_size=10,\n",
    "    local_epochs=5,\n",
    "    loss=\"CrossEntropyLoss\",\n",
    "    optimizer=DDict(\n",
    "      lr=0.01,\n",
    "      momentum=0.9,\n",
    "      weight_decay=0.0001),\n",
    "    scheduler=DDict(\n",
    "      gamma=1,\n",
    "      step_size=1),\n",
    "    malicious_percentage=0.2,\n",
    ")\n",
    "\n",
    "# we put together the hyperparameters for the algorithm\n",
    "hyperparams = DDict(client=client_hp,\n",
    "                    server=DDict(weighted=True, m=2),\n",
    "                    model=\"MNIST_2NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where the new federated algorithm comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " previous labels tensor([1, 6, 6,  ..., 9, 7, 2])\n",
      "{0: 9, 1: 2, 2: 5, 3: 1, 4: 3, 5: 6, 6: 4, 7: 8, 8: 0, 9: 7}\n",
      " post labels tensor([2, 4, 4,  ..., 7, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "algorithm = MyFLAlgorithm(n_clients=10, # 10 clients in the federation\n",
    "                          data_splitter=splitter,\n",
    "                          hyper_params=hyperparams)\n",
    "\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only just need to run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────── Round: 1 ────────────────────────────────────────────╮\n",
       "│ <span style=\"font-weight: bold\">{</span>                                                                                                │\n",
       "│     <span style=\"color: #008000; text-decoration-color: #008000\">'global'</span>: <span style=\"font-weight: bold\">{</span>                                                                                  │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1043</span>,                                                                      │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'macro_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0901</span>,                                                               │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'macro_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.10266</span>,                                                                 │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'macro_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.07131</span>,                                                                     │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'micro_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1043</span>,                                                               │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'micro_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1043</span>,                                                                  │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'micro_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1043</span>,                                                                      │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'round'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                                               │\n",
       "│     <span style=\"font-weight: bold\">}</span>,                                                                                           │\n",
       "│     <span style=\"color: #008000; text-decoration-color: #008000\">'comm_cost'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3562200</span>                                                                         │\n",
       "│ <span style=\"font-weight: bold\">}</span>                                                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────────── Round: 1 ────────────────────────────────────────────╮\n",
       "│ \u001b[1m{\u001b[0m                                                                                                │\n",
       "│     \u001b[32m'global'\u001b[0m: \u001b[1m{\u001b[0m                                                                                  │\n",
       "│         \u001b[32m'accuracy'\u001b[0m: \u001b[1;36m0.1043\u001b[0m,                                                                      │\n",
       "│         \u001b[32m'macro_precision'\u001b[0m: \u001b[1;36m0.0901\u001b[0m,                                                               │\n",
       "│         \u001b[32m'macro_recall'\u001b[0m: \u001b[1;36m0.10266\u001b[0m,                                                                 │\n",
       "│         \u001b[32m'macro_f1'\u001b[0m: \u001b[1;36m0.07131\u001b[0m,                                                                     │\n",
       "│         \u001b[32m'micro_precision'\u001b[0m: \u001b[1;36m0.1043\u001b[0m,                                                               │\n",
       "│         \u001b[32m'micro_recall'\u001b[0m: \u001b[1;36m0.1043\u001b[0m,                                                                  │\n",
       "│         \u001b[32m'micro_f1'\u001b[0m: \u001b[1;36m0.1043\u001b[0m,                                                                      │\n",
       "│         \u001b[32m'round'\u001b[0m: \u001b[1;36m1\u001b[0m                                                                               │\n",
       "│     \u001b[1m}\u001b[0m,                                                                                           │\n",
       "│     \u001b[32m'comm_cost'\u001b[0m: \u001b[1;36m3562200\u001b[0m                                                                         │\n",
       "│ \u001b[1m}\u001b[0m                                                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Memory usage: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">268.8</span> MB <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.20</span> %<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Memory usage: \u001b[1;36m268.8\u001b[0m MB \u001b[1m[\u001b[0m\u001b[1;36m4.20\u001b[0m %\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; font-style: italic\">The experiment has been interrupted by the user.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;3;33mThe experiment has been interrupted by the user.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ff1b7d27f042b6a9ecd6a0f4414f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────────── Overall Performance ───────────────────────────────────────╮\n",
       "│ <span style=\"font-weight: bold\">{</span>                                                                                                │\n",
       "│     <span style=\"color: #008000; text-decoration-color: #008000\">'global'</span>: <span style=\"font-weight: bold\">{</span>                                                                                  │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'accuracy'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1043</span>,                                                                      │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'macro_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0901</span>,                                                               │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'macro_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.10266</span>,                                                                 │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'macro_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.07131</span>,                                                                     │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'micro_precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1043</span>,                                                               │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'micro_recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1043</span>,                                                                  │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'micro_f1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1043</span>,                                                                      │\n",
       "│         <span style=\"color: #008000; text-decoration-color: #008000\">'round'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                                               │\n",
       "│     <span style=\"font-weight: bold\">}</span>,                                                                                           │\n",
       "│     <span style=\"color: #008000; text-decoration-color: #008000\">'comm_costs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6055740</span>                                                                        │\n",
       "│ <span style=\"font-weight: bold\">}</span>                                                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────────── Overall Performance ───────────────────────────────────────╮\n",
       "│ \u001b[1m{\u001b[0m                                                                                                │\n",
       "│     \u001b[32m'global'\u001b[0m: \u001b[1m{\u001b[0m                                                                                  │\n",
       "│         \u001b[32m'accuracy'\u001b[0m: \u001b[1;36m0.1043\u001b[0m,                                                                      │\n",
       "│         \u001b[32m'macro_precision'\u001b[0m: \u001b[1;36m0.0901\u001b[0m,                                                               │\n",
       "│         \u001b[32m'macro_recall'\u001b[0m: \u001b[1;36m0.10266\u001b[0m,                                                                 │\n",
       "│         \u001b[32m'macro_f1'\u001b[0m: \u001b[1;36m0.07131\u001b[0m,                                                                     │\n",
       "│         \u001b[32m'micro_precision'\u001b[0m: \u001b[1;36m0.1043\u001b[0m,                                                               │\n",
       "│         \u001b[32m'micro_recall'\u001b[0m: \u001b[1;36m0.1043\u001b[0m,                                                                  │\n",
       "│         \u001b[32m'micro_f1'\u001b[0m: \u001b[1;36m0.1043\u001b[0m,                                                                      │\n",
       "│         \u001b[32m'round'\u001b[0m: \u001b[1;36m1\u001b[0m                                                                               │\n",
       "│     \u001b[1m}\u001b[0m,                                                                                           │\n",
       "│     \u001b[32m'comm_costs'\u001b[0m: \u001b[1;36m6055740\u001b[0m                                                                        │\n",
       "│ \u001b[1m}\u001b[0m                                                                                                │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algorithm.run(n_rounds=3, eligible_perc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
