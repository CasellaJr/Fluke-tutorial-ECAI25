{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New federated Aggregation with `fluke`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will guide you through the steps required to implement KRUM and Multi-KRUM with ``fluke``.\n",
    "\n",
    "```{attention}\n",
    "This tutorial does not go into the details of the implementation, but it provides a quick overview of the steps required to implement a new federated learning algorithm.\n",
    "```\n",
    "\n",
    "Try this notebook: [![Open in Colab](https://img.shields.io/badge/Open_in_Colab-blue?style=flat-square&logo=google-colab&logoColor=yellow&labelColor=gray)\n",
    "](https://colab.research.google.com/github/CasellaJr/Fluke-tutorial-ECAI25/blob/main/2_fluke_krum.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install `fluke` (if not already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fluke-fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KRUM\n",
    "\n",
    "Let's do a further operation, let's implement KRUM aggregation, that should be more robust to byzantine attacks than the median aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Iterable\n",
    "from torch.nn import Module\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "\n",
    "from fluke.client import Client\n",
    "from fluke.server import Server\n",
    "from fluke.data import FastDataLoader\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "class KRUMServer(Server):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        test_set: FastDataLoader | None,\n",
    "        clients: Sequence[Client],\n",
    "        weighted: bool = False,\n",
    "        lr: float = 1.0,\n",
    "        f: int = 0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(model, test_set, clients, weighted, lr, **kwargs)\n",
    "        self.hyper_params.update(f=f)\n",
    "\n",
    "\n",
    "    def aggregate(self, eligible: Sequence[Client], client_models: Iterable[Module]) -> None:\n",
    "\n",
    "        client_models = list(client_models)\n",
    "        n = len(client_models)\n",
    "        f = self.hyper_params.f\n",
    "\n",
    "        server_param_items = list(self.model.named_parameters())\n",
    "        param_keys = [k for k, _ in server_param_items]\n",
    "\n",
    "        # get one vector for each client\n",
    "        client_vecs = []\n",
    "        for i, cm in enumerate(client_models):\n",
    "            cm_state = dict(cm.named_parameters())\n",
    "            parts = [torch.ravel(cm_state[k].data) for k in param_keys]\n",
    "            vec = torch.cat(parts, dim=0)\n",
    "            client_vecs.append(vec)\n",
    "\n",
    "        # put all these vector in a tensor\n",
    "        mat = torch.stack(client_vecs, dim=0)\n",
    "\n",
    "        # calculate pairwise euclidean distance matrix to extract the scores\n",
    "        dists = torch.cdist(mat, mat, p=2.0)  # shape (n, n)\n",
    "        sq_dists = dists.pow(2)\n",
    "\n",
    "        scores = torch.empty(n)\n",
    "        # For each model i, sort distances to others (exclude self-distance=0)\n",
    "        # and sum the smallest (n - f - 2) distances\n",
    "        nb_small = n - f - 2\n",
    "        for i in range(n):\n",
    "            # distances to others (includes zero at i)\n",
    "            row = sq_dists[i]\n",
    "            # Get sorted distances (ascending)\n",
    "            sorted_row, _ = torch.sort(row)\n",
    "            selected = sorted_row[1: nb_small + 1]\n",
    "            scores[i] = selected.sum()\n",
    "\n",
    "        _, selected_indices = torch.topk(scores, k=1, largest=False)\n",
    "\n",
    "        selected_indices = selected_indices.tolist()  # indices of chosen clients\n",
    "\n",
    "        chosen_idx = selected_indices[0]\n",
    "        chosen_state = dict(client_models[chosen_idx].named_parameters())\n",
    "        # Copy parameter tensors into server model\n",
    "        for k in param_keys:\n",
    "            self.model.state_dict()[k].copy_(chosen_state[k].data)\n",
    "\n",
    "        return deepcopy(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the new federated algorithm\n",
    "\n",
    "Now, we only need to put everything together in a new class that inherits from `fluke.algorithms.CentralizedFL` specifying the server class we just implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.algorithms import CentralizedFL\n",
    "\n",
    "class KRUMFLAlgorithm(CentralizedFL):\n",
    "\n",
    "    def get_server_class(self) -> type[Server]:\n",
    "        return KRUMServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is ready! Now we can test our new federated algorithm with `fluke`!\n",
    "\n",
    "## Ready to test KRUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.data import DataSplitter\n",
    "from fluke.data.datasets import Datasets\n",
    "from fluke import DDict\n",
    "from fluke.utils.log import Log\n",
    "from fluke.evaluation import ClassificationEval\n",
    "from fluke import FlukeENV\n",
    "\n",
    "env = FlukeENV()\n",
    "env.set_seed(42) # we set a seed for reproducibility\n",
    "env.set_device(\"cpu\") # we use the CPU for this example\n",
    "\n",
    "dataset = Datasets.get(\"mnist\", path=\"./data\")\n",
    "\n",
    "# we set the evaluator to be used by both the server and the clients\n",
    "env.set_evaluator(ClassificationEval(eval_every=1, n_classes=dataset.num_classes))\n",
    "\n",
    "splitter = DataSplitter(dataset=dataset,\n",
    "                        distribution=\"iid\")\n",
    "\n",
    "client_hp = DDict(\n",
    "    batch_size=10,\n",
    "    local_epochs=5,\n",
    "    loss=\"CrossEntropyLoss\",\n",
    "    optimizer=DDict(\n",
    "      lr=0.01,\n",
    "      momentum=0.9,\n",
    "      weight_decay=0.0001),\n",
    "    scheduler=DDict(\n",
    "      gamma=1,\n",
    "      step_size=1)\n",
    ")\n",
    "\n",
    "# we put together the hyperparameters for the algorithm\n",
    "hyperparams = DDict(client=client_hp,\n",
    "                    server=DDict(weighted=True, f=7),\n",
    "                    model=\"MNIST_2NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where the new federated algorithm comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = KRUMFLAlgorithm(n_clients=10, # 10 clients in the federation\n",
    "                            data_splitter=splitter,\n",
    "                            hyper_params=hyperparams)\n",
    "\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)\n",
    "logger.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm.run(n_rounds=3, eligible_perc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-KRUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiKRUMServer(Server):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        test_set: FastDataLoader | None,\n",
    "        clients: Sequence[Client],\n",
    "        weighted: bool = False,\n",
    "        lr: float = 1.0,\n",
    "        f: int = 0,\n",
    "        m: int = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(model, test_set, clients, weighted, lr, **kwargs)\n",
    "        self.hyper_params.update(f=f, m=m)\n",
    "\n",
    "\n",
    "    def aggregate(self, eligible: Sequence[Client], client_models: Iterable[Module]) -> None:\n",
    "\n",
    "            client_models = list(client_models)\n",
    "            n = len(client_models)\n",
    "            f = self.hyper_params.f\n",
    "\n",
    "            server_param_items = list(self.model.named_parameters())\n",
    "            param_keys = [k for k, _ in server_param_items]\n",
    "\n",
    "            # get one vector for each client\n",
    "            client_vecs = []\n",
    "            for i, cm in enumerate(client_models):\n",
    "                cm_state = dict(cm.named_parameters())\n",
    "                parts = [torch.ravel(cm_state[k].data) for k in param_keys]\n",
    "                vec = torch.cat(parts, dim=0)\n",
    "                client_vecs.append(vec)\n",
    "\n",
    "            # put all these vector in a tensor\n",
    "            mat = torch.stack(client_vecs, dim=0)\n",
    "\n",
    "            # calculate pairwise euclidean distance matrix to extract the scores\n",
    "            dists = torch.cdist(mat, mat, p=2.0)  # shape (n, n)\n",
    "            sq_dists = dists.pow(2)\n",
    "\n",
    "            scores = torch.empty(n)\n",
    "            # For each model i, sort distances to others (exclude self-distance=0)\n",
    "            # and sum the smallest (n - f - 2) distances\n",
    "            nb_small = n - f - 2\n",
    "            for i in range(n):\n",
    "                # distances to others (includes zero at i)\n",
    "                row = sq_dists[i]\n",
    "                # Get sorted distances (ascending)\n",
    "                sorted_row, _ = torch.sort(row)\n",
    "                selected = sorted_row[1: nb_small + 1]\n",
    "                scores[i] = selected.sum()\n",
    "\n",
    "            _, selected_indices = torch.topk(scores, k=self.hyper_params.m, largest=False)\n",
    "\n",
    "            selected_indices = selected_indices.tolist()  # indices of chosen clients\n",
    "\n",
    "            # If m == 1: KRUM\n",
    "            if self.hyper_params.m == 1:\n",
    "                chosen_idx = selected_indices[0]\n",
    "                chosen_state = dict(client_models[chosen_idx].named_parameters())\n",
    "                # Copy parameter tensors into server model\n",
    "                for k in param_keys:\n",
    "                    self.model.state_dict()[k].copy_(chosen_state[k].data)\n",
    "            else:\n",
    "                # Multi-KRUM: average the selected m models elementwise (simple mean)\n",
    "                # We'll build averaged parameters by stacking the selected params and mean them\n",
    "                # Using named_parameters order to assemble results\n",
    "                # Initialize accumulator dict of tensors (float) on server device\n",
    "                accum = {}\n",
    "                for k in param_keys:\n",
    "                    first_t = client_models[selected_indices[0]].state_dict()[k].data\n",
    "                    accum[k] = first_t.clone().detach().float()  # use float accumulation\n",
    "\n",
    "                for idx in selected_indices[1:]:\n",
    "                    cm_state = client_models[idx].state_dict()\n",
    "                    for k in param_keys:\n",
    "                        accum[k].add_(cm_state[k].data)\n",
    "\n",
    "                # divide by m and copy back\n",
    "                for k in param_keys:\n",
    "                    mean_t = (accum[k] / float(self.hyper_params.m)).to(self.model.state_dict()[k].dtype)\n",
    "                    self.model.state_dict()[k].copy_(mean_t)\n",
    "\n",
    "            return deepcopy(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.algorithms import CentralizedFL\n",
    "\n",
    "class MultiKRUMFLAlgorithm(CentralizedFL):\n",
    "\n",
    "    def get_server_class(self) -> type[Server]:\n",
    "        return MultiKRUMServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = MultiKRUMFLAlgorithm(n_clients=10, # 10 clients in the federation\n",
    "                                data_splitter=splitter,\n",
    "                                hyper_params=hyperparams)\n",
    "\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)\n",
    "logger.init()\n",
    "algorithm.run(n_rounds=3, eligible_perc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implmenting malicious clients\n",
    "\n",
    "We implement a simple malicious client that sends random model updates to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "from fluke.client import Client\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "class RandomClient(Client):\n",
    "    def __init__(self, malicious_percentage: float = 0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.malicious = torch.rand(1).item() < malicious_percentage\n",
    "\n",
    "    def fit(self, override_local_epochs = 0):\n",
    "        if self.malicious:\n",
    "            for param in self.model.parameters():\n",
    "                param.data = torch.randn_like(param)\n",
    "        else:\n",
    "            super().fit(override_local_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to create a FedAVG federation where some clients are malicious and send random updates to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackFLAlgorithm(CentralizedFL):\n",
    "\n",
    "    def get_client_class(self) -> type[Client]:\n",
    "        return RandomClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_hp = DDict(\n",
    "    batch_size=10,\n",
    "    local_epochs=5,\n",
    "    loss=\"CrossEntropyLoss\",\n",
    "    optimizer=DDict(\n",
    "        lr=0.01,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001),\n",
    "    scheduler=DDict(\n",
    "        gamma=1,\n",
    "        step_size=1),\n",
    "    malicious_percentage=0.4 ## 40% of clients are malicious\n",
    ")\n",
    "\n",
    "# we put together the hyperparameters for the algorithm\n",
    "hyperparams = DDict(client=client_hp,\n",
    "                    server=DDict(weighted=True),\n",
    "                    model=\"MNIST_2NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = AttackFLAlgorithm(\n",
    "    n_clients=10, # 10 clients in the federation\n",
    "    data_splitter=splitter,\n",
    "    hyper_params=hyperparams\n",
    ")\n",
    "\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)\n",
    "logger.init()\n",
    "algorithm.run(n_rounds=3, eligible_perc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the defence\n",
    "\n",
    "Let's now implement the defence mechanism, that is, KRUM aggregation rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackDefenceFLAlgorithm(CentralizedFL):\n",
    "\n",
    "    def get_server_class(self) -> type[Server]:\n",
    "        return KRUMServer\n",
    "\n",
    "    def get_client_class(self) -> type[Client]:\n",
    "        return RandomClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = AttackDefenceFLAlgorithm(\n",
    "    n_clients=10, # 10 clients in the federation\n",
    "    data_splitter=splitter,\n",
    "    hyper_params=hyperparams\n",
    ")\n",
    "\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)\n",
    "logger.init()\n",
    "algorithm.run(n_rounds=3, eligible_perc=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the Multi-KRUM aggregation rule in the presence of malicious clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackDefenceFLAlgorithm(CentralizedFL):\n",
    "\n",
    "    def get_server_class(self) -> type[Server]:\n",
    "        return MultiKRUMServer\n",
    "\n",
    "    def get_client_class(self) -> type[Client]:\n",
    "        return RandomClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = AttackDefenceFLAlgorithm(\n",
    "    n_clients=10, # 10 clients in the federation\n",
    "    data_splitter=splitter,\n",
    "    hyper_params=hyperparams\n",
    ")\n",
    "\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)\n",
    "logger.init()\n",
    "algorithm.run(n_rounds=3, eligible_perc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluke-tutorial (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
